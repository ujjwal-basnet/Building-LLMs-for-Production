{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce2c4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import logging # Import logging early\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Your familiar email sending/fetching variables\n",
    "APP_PASSWORD = os.getenv('app_password')\n",
    "SENDER_EMAIL = os.getenv('sender')\n",
    "\n",
    "# Split recipients by comma if it's a string from .env\n",
    "RECIPIENTS_STR = os.getenv('recipients1', '')\n",
    "RECIPIENTS = [r.strip() for r in RECIPIENTS_STR.split(',') if r.strip()]\n",
    "\n",
    "# For IMAP, you explicitly mentioned GMAIL_EMAIL in your example\n",
    "GMAIL_IMAP_EMAIL = os.getenv(\"GMAIL_EMAIL\", SENDER_EMAIL) # Fallback to SENDER_EMAIL if not set\n",
    "\n",
    "# OpenRouter API Key for AI models\n",
    "# OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dca0369",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENROUTER_API_KEY= os.getenv('openai_api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81ee8ec9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'No auth credentials found', 'code': 401}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m model_filtering = ChatOpenAI(\n\u001b[32m      2\u001b[39m     base_url=\u001b[33m\"\u001b[39m\u001b[33mhttps://openrouter.ai/api/v1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mdeepseek/deepseek-chat\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m     max_retries=\u001b[32m5\u001b[39m\n\u001b[32m      7\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mmodel_filtering\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ujjwal\\Building-LLMs-for-Production\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:378\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    368\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m     **kwargs: Any,\n\u001b[32m    374\u001b[39m ) -> BaseMessage:\n\u001b[32m    375\u001b[39m     config = ensure_config(config)\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    377\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    388\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ujjwal\\Building-LLMs-for-Production\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    956\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    960\u001b[39m     **kwargs: Any,\n\u001b[32m    961\u001b[39m ) -> LLMResult:\n\u001b[32m    962\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ujjwal\\Building-LLMs-for-Production\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    781\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    790\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ujjwal\\Building-LLMs-for-Production\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1026\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1032\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ujjwal\\Building-LLMs-for-Production\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1130\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1128\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m   1129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1130\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ujjwal\\Building-LLMs-for-Production\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ujjwal\\Building-LLMs-for-Production\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1087\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1044\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1084\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1085\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1086\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1087\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1118\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ujjwal\\Building-LLMs-for-Production\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1256\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1243\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1244\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1251\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1252\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1253\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1254\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1255\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ujjwal\\Building-LLMs-for-Production\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1044\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1041\u001b[39m             err.response.read()\n\u001b[32m   1043\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'No auth credentials found', 'code': 401}}"
     ]
    }
   ],
   "source": [
    "model_filtering = ChatOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"deepseek/deepseek-chat\",\n",
    "    temperature=0.0,\n",
    "    openai_api_key=OPENROUTER_API_KEY,\n",
    "    max_retries=5\n",
    ")\n",
    "\n",
    "\n",
    "model_filtering.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d187d0",
   "metadata": {},
   "source": [
    "#agents \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea0e10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imaplib\n",
    "import email\n",
    "from email.header import decode_header\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import smtplib\n",
    "import ssl\n",
    "import re\n",
    "from typing import List, Dict, Any, TypedDict\n",
    "import pandas as pd # For potential DataFrame use, although not strictly required by the core logic\n",
    "\n",
    "# Langchain and LangGraph imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "\n",
    "## Utils: Logger\n",
    "def get_logger(name):\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    ch.setFormatter(formatter)\n",
    "\n",
    "    # Avoid adding duplicate handlers in Jupyter re-runs\n",
    "    if not logger.handlers:\n",
    "        logger.addHandler(ch)\n",
    "\n",
    "    return logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "## Core: EmailState (TypedDict)\n",
    "class EmailState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of an email as it moves through the processing pipeline.\n",
    "    \"\"\"\n",
    "    emails: List[Dict[str, Any]]\n",
    "    current_email: Dict[str, Any]\n",
    "    history: List[Dict[str, Any]]\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "\n",
    "## Core: Email Fetching (Adapted to imaplib.IMAP4_SSL)\n",
    "def decode_email_header(header):\n",
    "    \"\"\"Decodes email headers that might contain non-ASCII characters.\"\"\"\n",
    "    decoded_parts = decode_header(header)\n",
    "    decoded_string = \"\"\n",
    "    for part, charset in decoded_parts:\n",
    "        if isinstance(part, bytes):\n",
    "            try:\n",
    "                decoded_string += part.decode(charset if charset else 'utf-8')\n",
    "            except (UnicodeDecodeError, LookupError):\n",
    "                decoded_string += part.decode('latin-1', errors='ignore') # Fallback\n",
    "        else:\n",
    "            decoded_string += part\n",
    "    return decoded_string\n",
    "\n",
    "def fetch_imap_emails(imap_username: str, app_password: str, num_emails: int = 5) -> list:\n",
    "    \"\"\"\n",
    "    Fetches emails from an IMAP server using imaplib.IMAP4_SSL.\n",
    "    \"\"\"\n",
    "    emails = []\n",
    "    IMAP_SERVER = \"imap.gmail.com\" # Hardcoded for Gmail as per your example\n",
    "\n",
    "    try:\n",
    "        mail = imaplib.IMAP4_SSL(IMAP_SERVER)\n",
    "        logger.info(f\"Connecting to IMAP server: {IMAP_SERVER} with username: {imap_username}\")\n",
    "        mail.login(imap_username, app_password)\n",
    "        logger.info(\"IMAP login successful.\")\n",
    "        mail.select(\"inbox\")\n",
    "        logger.info(\"Selected INBOX folder.\")\n",
    "\n",
    "        status, messages = mail.search(None, \"ALL\")\n",
    "\n",
    "        if status != \"OK\":\n",
    "            logger.warning(\"No messages found in INBOX.\")\n",
    "            return []\n",
    "\n",
    "        email_ids = messages[0].split()\n",
    "        logger.debug(f\"Found {len(email_ids)} messages.\")\n",
    "\n",
    "        # Fetch the latest N messages\n",
    "        fetch_uids = email_ids[-num_emails:] if len(email_ids) > num_emails else email_ids\n",
    "\n",
    "        if not fetch_uids:\n",
    "            logger.info(\"No messages to fetch.\")\n",
    "            return []\n",
    "\n",
    "        for uid in fetch_uids:\n",
    "            status, msg_data = mail.fetch(uid, \"(RFC822)\")\n",
    "            if status != \"OK\":\n",
    "                logger.error(f\"Failed to fetch email UID {uid}: {msg_data}\")\n",
    "                continue\n",
    "\n",
    "            raw_email = msg_data[0][1]\n",
    "            msg = email.message_from_bytes(raw_email)\n",
    "\n",
    "            subject = decode_email_header(msg.get('Subject', 'No Subject'))\n",
    "            sender_raw = msg.get('From', 'Unknown Sender')\n",
    "            sender = decode_email_header(sender_raw)\n",
    "\n",
    "            body = \"\"\n",
    "            if msg.is_multipart():\n",
    "                for part in msg.walk():\n",
    "                    ctype = part.get_content_type()\n",
    "                    cdispo = str(part.get('Content-Disposition'))\n",
    "\n",
    "                    if ctype == 'text/plain' and 'attachment' not in cdispo:\n",
    "                        try:\n",
    "                            body = part.get_payload(decode=True).decode(part.get_content_charset() or 'utf-8', errors='ignore')\n",
    "                        except (UnicodeDecodeError, LookupError):\n",
    "                            body = part.get_payload(decode=True).decode('latin-1', errors='ignore')\n",
    "                        break\n",
    "            else:\n",
    "                try:\n",
    "                    body = msg.get_payload(decode=True).decode(msg.get_content_charset() or 'utf-8', errors='ignore')\n",
    "                except (UnicodeDecodeError, LookupError):\n",
    "                    body = msg.get_payload(decode=True).decode('latin-1', errors='ignore')\n",
    "\n",
    "            emails.append({\n",
    "                \"id\": uid.decode(), # Decode UID from bytes to string\n",
    "                \"subject\": subject,\n",
    "                \"sender\": sender,\n",
    "                \"body\": body,\n",
    "                \"raw_message\": raw_email\n",
    "            })\n",
    "        logger.info(f\"Successfully fetched {len(emails)} emails.\")\n",
    "\n",
    "    except imaplib.IMAP4.error as e:\n",
    "        logger.error(f\"IMAP Error: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred while fetching emails: {e}\")\n",
    "    finally:\n",
    "        try:\n",
    "            if 'mail' in locals() and mail.state == 'SELECTED':\n",
    "                mail.close()\n",
    "            if 'mail' in locals() and mail.state == 'AUTH':\n",
    "                mail.logout()\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error during IMAP logout: {e}\")\n",
    "    return emails\n",
    "\n",
    "\n",
    "## Core: Email Sending (Adapted to smtplib.SMTP_SSL)\n",
    "def send_email_smtp(subject: str, body: str, sender: str, recipients: List[str], password: str) -> bool:\n",
    "    \"\"\"\n",
    "    Connects to Gmail's SMTP server using SMTP_SSL and sends an email.\n",
    "    \"\"\"\n",
    "    msg = MIMEText(body)\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = ', '.join(recipients)\n",
    "\n",
    "    try:\n",
    "        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp_server:\n",
    "            smtp_server.login(sender, password)\n",
    "            smtp_server.sendmail(sender, recipients, msg.as_string())\n",
    "        logger.info(f\"Email sent from {sender} to {recipients} with subject '{subject}'.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to send email. Error: {e}\")\n",
    "        logger.error(\"Please check: 1. Your 'sender' email and 'app_password' are correct. 2. Internet connection.\")\n",
    "        return False\n",
    "\n",
    "# Re-implement send_email and send_draft_to_gmail to use the new send_email_smtp\n",
    "def send_email(email_data: dict, your_name: str, sender_email_address: str, sender_app_password: str) -> bool:\n",
    "    \"\"\"Wrapper for the core send_email_smtp for the AI agent context.\"\"\"\n",
    "    recipient_email_raw = email_data.get(\"sender\", \"unknown@example.com\")\n",
    "    match = re.search(r'<(.*?)>', recipient_email_raw)\n",
    "    recipient_email = match.group(1) if match else recipient_email_raw\n",
    "\n",
    "    subject = f\"Re: {email_data.get('subject', 'No Subject')}\"\n",
    "    body = email_data.get(\"response\", \"No response generated.\")\n",
    "\n",
    "    return send_email_smtp(subject, body, sender_email_address, [recipient_email], sender_app_password)\n",
    "\n",
    "\n",
    "def send_draft_to_gmail(email_data: dict, your_name: str, gmail_address: str, gmail_app_password: str) -> bool:\n",
    "    \"\"\"Wrapper for the core send_email_smtp for drafting purposes.\"\"\"\n",
    "    logger.warning(\"Sending draft to Gmail address as a regular email. For true 'Drafts' functionality, Gmail API is generally required.\")\n",
    "\n",
    "    subject = f\"DRAFT: Re: {email_data.get('subject', 'No Subject')}\"\n",
    "    body = email_data.get(\"response\", \"No response generated.\")\n",
    "\n",
    "    return send_email_smtp(subject, body, gmail_address, [gmail_address], gmail_app_password)\n",
    "\n",
    "\n",
    "## Agents: Filtering\n",
    "model_filtering = ChatOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"deepseek/deepseek-chat\",\n",
    "    temperature=0.0,\n",
    "    openai_api_key=OPENROUTER_API_KEY,\n",
    "    max_retries=5\n",
    ")\n",
    "\n",
    "def filter_email(email: dict) -> str:\n",
    "    \"\"\"\n",
    "    Classifies an email into Spam, Urgent, Needs Review, or Informational categories.\n",
    "    \"\"\"\n",
    "    subject = email.get(\"subject\", \"\")\n",
    "    body = email.get(\"body\", \"\")\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an expert email classifier. Your task is to categorize emails into one of the following:\n",
    "        - 'spam': Unsolicited commercial email, phishing attempts, or suspicious content.\n",
    "        - 'urgent': Emails requiring immediate attention or action.\n",
    "        - 'needs_review': Emails that require human discretion, contain ambiguous information, or might be important but not urgent.\n",
    "        - 'informational': Emails that are for general information, newsletters, or routine updates, requiring no immediate action.\n",
    "\n",
    "        Analyze the subject and body of the email to make an accurate classification.\n",
    "        Output only the category name (e.g., 'spam', 'urgent', 'needs_review', 'informational').\"\"\"),\n",
    "        (\"human\", \"Subject: {subject}\\n\\nBody: {body}\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | model_filtering | StrOutputParser()\n",
    "\n",
    "    try:\n",
    "        classification = chain.invoke({\"subject\": subject, \"body\": body}).strip().lower()\n",
    "        logger.info(f\"Email ID: {email.get('id', 'unknown')} classified as: {classification}\")\n",
    "\n",
    "        valid_categories = {\"spam\", \"urgent\", \"needs_review\", \"informational\"}\n",
    "        if classification not in valid_categories:\n",
    "            logger.warning(f\"Unexpected classification received: {classification}. Defaulting to 'needs_review'.\")\n",
    "            return \"needs_review\"\n",
    "\n",
    "        return classification\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error classifying email {email.get('id', 'unknown')}: {e}\")\n",
    "        return \"needs_review\"\n",
    "\n",
    "\n",
    "## Agents: Summarization\n",
    "model_summarization = ChatOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"deepseek/deepseek-chat\",\n",
    "    temperature=0.7,\n",
    "    openai_api_key=OPENROUTER_API_KEY,\n",
    "    max_retries=5\n",
    ")\n",
    "\n",
    "def summarize_email(email: dict) -> str:\n",
    "    \"\"\"\n",
    "    Generates a brief summary of the email content.\n",
    "    \"\"\"\n",
    "    subject = email.get(\"subject\", \"\")\n",
    "    body = email.get(\"body\", \"\")\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a concise email summarizer. Your task is to provide a brief,\n",
    "        accurate summary of the email's key points. Focus on the main message and any\n",
    "        actionable items. Keep the summary to 2-3 sentences.\"\"\"),\n",
    "        (\"human\", \"Subject: {subject}\\n\\nBody: {body}\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | model_summarization | StrOutputParser()\n",
    "\n",
    "    try:\n",
    "        summary = chain.invoke({\"subject\": subject, \"body\": body}).strip()\n",
    "        logger.info(f\"Email ID: {email.get('id', 'unknown')} summarized.\")\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error summarizing email {email.get('id', 'unknown')}: {e}\")\n",
    "        return \"Could not generate summary.\"\n",
    "\n",
    "\n",
    "## Agents: Response Generation\n",
    "model_response = ChatOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"deepseek/deepseek-chat\",\n",
    "    temperature=0.8,\n",
    "    openai_api_key=OPENROUTER_API_KEY,\n",
    "    max_retries=5\n",
    ")\n",
    "\n",
    "def format_email_response_text(original_subject: str, recipient_name: str, response_text: str, your_name: str) -> str:\n",
    "    \"\"\"Formats the generated response into a proper email format.\"\"\"\n",
    "    return (\n",
    "        f\"Subject: Re: {original_subject}\\n\\n\"\n",
    "        f\"Hi {recipient_name},\\n\\n\"\n",
    "        f\"{response_text}\\n\\n\"\n",
    "        f\"Best regards,\\n\"\n",
    "        f\"{your_name}\"\n",
    "    )\n",
    "\n",
    "def generate_response(email: dict, summary: str, recipient_name: str, your_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a suitable email reply based on the email summary and original details.\n",
    "    \"\"\"\n",
    "    subject = email.get(\"subject\", \"\")\n",
    "    sender = email.get(\"sender\", \"The sender\")\n",
    "    body = email.get(\"body\", \"\")\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an AI email assistant. Your task is to craft a polite, relevant, and concise email reply.\n",
    "        Consider the email's subject, sender, and the provided summary.\n",
    "\n",
    "        If the email is 'informational', a brief acknowledgment or \"thank you\" is usually sufficient.\n",
    "        If it's 'urgent' or 'needs_review', suggest next steps or ask clarifying questions.\n",
    "\n",
    "        Aim for a professional and helpful tone. Do not include subject lines or greetings/signatures in your direct response,\n",
    "        just the body of the reply.\"\"\"),\n",
    "        (\"human\", \"Original Subject: {subject}\\nFrom: {sender}\\nSummary of email: {summary}\\n\\nGenerate a suitable reply:\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | model_response | StrOutputParser()\n",
    "\n",
    "    try:\n",
    "        response_content = chain.invoke({\n",
    "            \"subject\": subject,\n",
    "            \"sender\": sender,\n",
    "            \"summary\": summary\n",
    "        }).strip()\n",
    "\n",
    "        if \"?\" in response_content or \"I am unsure\" in response_content.lower():\n",
    "            logger.info(f\"Response for email ID: {email.get('id', 'unknown')} flagged for human review (uncertainty detected).\")\n",
    "            response_content = \"[[REVIEW REQUIRED]] \" + response_content\n",
    "\n",
    "        formatted_response = format_email_response_text(subject, recipient_name, response_content, your_name)\n",
    "        logger.info(f\"Email ID: {email.get('id', 'unknown')} response generated.\")\n",
    "        return formatted_response\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating response for email {email.get('id', 'unknown')}: {e}\")\n",
    "        return format_email_response_text(subject, recipient_name, \"I apologize, but I was unable to generate a response at this time. Please review the original email.\", your_name)\n",
    "\n",
    "\n",
    "## Agents: Human Review\n",
    "def review_email(email: dict, current_response: str) -> str:\n",
    "    \"\"\"\n",
    "    Simulates a human review process for the generated email response.\n",
    "    Allows the user to modify the response.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Email ID: {email.get('id', 'unknown')} flagged for human review.\")\n",
    "    print(\"\\n--- Human Review Required ---\")\n",
    "    print(f\"Original Subject: {email.get('subject', 'N/A')}\")\n",
    "    print(f\"Original Sender: {email.get('sender', 'N/A')}\")\n",
    "    print(f\"Summary: {email.get('summary', 'N/A')}\")\n",
    "    print(\"\\nAI Generated Response:\")\n",
    "    print(current_response)\n",
    "\n",
    "    while True:\n",
    "        action = input(\"\\nDo you want to (e)dit, (a)ccept, or (r)eject this response? (e/a/r): \").strip().lower()\n",
    "        if action == 'e':\n",
    "            modified_response = input(\"Enter your modified response: \\n\")\n",
    "            logger.info(\"Human edited the response.\")\n",
    "            return modified_response\n",
    "        elif action == 'a':\n",
    "            logger.info(\"Human accepted the response as is.\")\n",
    "            return current_response\n",
    "        elif action == 'r':\n",
    "            logger.warning(\"Human rejected the response. No response will be sent.\")\n",
    "            return \"\"\n",
    "        else:\n",
    "            print(\"Invalid option. Please choose 'e', 'a', or 'r'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58f3d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Core: Supervisor\n",
    "def supervisor_langgraph(email: dict, state: EmailState, user_name: str, recipient_name: str) -> EmailState:\n",
    "    \"\"\"\n",
    "    Processes an individual email using a LangGraph workflow.\n",
    "    Each step (filtering, summarization, response generation) is a node.\n",
    "    Conditional edges are used to exit early for spam or to continue processing.\n",
    "    \"\"\"\n",
    "\n",
    "    state['current_email'] = email\n",
    "\n",
    "    def filtering_node(state: EmailState) -> EmailState:\n",
    "        current_email = state['current_email']\n",
    "        email_id = current_email.get(\"id\", \"unknown\")\n",
    "        logger.info(f'Filtering node started for email ID: {email_id}')\n",
    "\n",
    "        classification = filter_email(current_email)\n",
    "        current_email[\"classification\"] = classification\n",
    "\n",
    "        if 'metadata' not in state:\n",
    "            state['metadata'] = {}\n",
    "        state['metadata'][email_id] = classification\n",
    "\n",
    "        logger.info(f'Email ID: {email_id} classified as: {classification}')\n",
    "        return state\n",
    "\n",
    "    def summarization_node(state: EmailState) -> EmailState:\n",
    "        email = state['current_email']\n",
    "        email_id = email.get(\"id\", \"unknown\")\n",
    "        logger.info(f'Summarization node started for email ID: {email_id}')\n",
    "\n",
    "        summary = summarize_email(email)\n",
    "        email[\"summary\"] = summary\n",
    "\n",
    "        logger.info(f'Email ID: {email_id} summarized.')\n",
    "        return state\n",
    "\n",
    "    def response_node(state: EmailState) -> EmailState:\n",
    "        email = state['current_email']\n",
    "        email_id = email.get(\"id\", \"unknown\")\n",
    "        logger.info(f'Response generation node started for email ID: {email_id}')\n",
    "\n",
    "        response = generate_response(email, email.get(\"summary\", \"\"), recipient_name, user_name)\n",
    "\n",
    "        needs_review_by_ai = \"[[REVIEW REQUIRED]]\" in response\n",
    "\n",
    "        if email.get(\"classification\") == \"needs_review\" or needs_review_by_ai:\n",
    "            logger.info(f\"Email ID: {email_id} flagged for human review by supervisor logic.\")\n",
    "            response = review_email(email, response.replace(\"[[REVIEW REQUIRED]]\", \"\").strip())\n",
    "\n",
    "        email[\"response\"] = response\n",
    "\n",
    "        if 'history' not in state:\n",
    "            state['history'] = []\n",
    "        state['history'].append({\n",
    "            \"email_id\": email_id,\n",
    "            \"response\": response\n",
    "        })\n",
    "\n",
    "        logger.info(f'Email ID: {email_id} response processed.')\n",
    "        return state\n",
    "\n",
    "    graph_builder = StateGraph(EmailState)\n",
    "\n",
    "    graph_builder.add_node(\"filtering\", filtering_node)\n",
    "    graph_builder.add_node(\"summarization\", summarization_node)\n",
    "    graph_builder.add_node(\"response\", response_node)\n",
    "\n",
    "    def post_filtering(state: EmailState):\n",
    "        email = state['current_email']\n",
    "        if email.get(\"classification\") == \"spam\":\n",
    "            logger.info(f\"Email ID: {email.get('id', 'unknown')} classified as SPAM. Terminating pipeline.\")\n",
    "            return END\n",
    "        else:\n",
    "            logger.info(f\"Email ID: {email.get('id', 'unknown')} not spam. Proceeding to summarization.\")\n",
    "            return \"summarization\"\n",
    "\n",
    "    graph_builder.add_conditional_edges(\"filtering\", post_filtering)\n",
    "    graph_builder.add_edge(\"summarization\", \"response\")\n",
    "    graph_builder.add_edge(\"response\", END)\n",
    "\n",
    "    graph_builder.set_entry_point(\"filtering\")\n",
    "\n",
    "    graph = graph_builder.compile()\n",
    "\n",
    "    logger.info(f\"Invoking LangGraph for email ID: {email.get('id', 'unknown')}\")\n",
    "    final_state = graph.invoke(state)\n",
    "    logger.info(f\"LangGraph processing finished for email ID: {email.get('id', 'unknown')}\")\n",
    "    return final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1608dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # Only needed if loading from JSON for testing\n",
    "\n",
    "def process_email_action(email_to_process, your_name, sender_email_address, sender_app_password):\n",
    "    \"\"\"\n",
    "    Prompts the user for action (send or draft) and executes it.\n",
    "    \"\"\"\n",
    "    action = input(\"Do you want to (s)end the email or (d)raft it to Gmail? (s/d): \").strip().lower()\n",
    "    if action == \"s\":\n",
    "        # Pass the actual sender email and app password\n",
    "        if send_email(email_to_process, your_name, sender_email_address, sender_app_password):\n",
    "            logger.info(\"Email sent successfully.\")\n",
    "        else:\n",
    "            logger.warning(\"Failed to send email.\")\n",
    "    elif action == \"d\":\n",
    "        # For drafting, we assume the draft will be sent to the sender_email_address itself.\n",
    "        # This acts as a 'sent to self' for review/drafting purposes.\n",
    "        if send_draft_to_gmail(email_to_process, your_name, sender_email_address, sender_app_password):\n",
    "            logger.info(\"Draft sent to Gmail successfully.\")\n",
    "        else:\n",
    "            logger.warning(\"Failed to send draft to Gmail.\")\n",
    "    else:\n",
    "        logger.warning(\"Invalid option. No action taken.\")\n",
    "\n",
    "def run_email_agent():\n",
    "    logger.info(\"Starting AI Email Agent.\")\n",
    "\n",
    "    your_name = input(\"Please enter your name (for signature): \")\n",
    "    recipient_name = input(\"Please enter the recipient's name (e.g., John Doe): \")\n",
    "\n",
    "    emails = []\n",
    "\n",
    "    data_source = input(\"Fetch emails live (l) or load from JSON (j)? (l/j): \").strip().lower()\n",
    "\n",
    "    if data_source == 'l':\n",
    "        if not (GMAIL_IMAP_EMAIL and APP_PASSWORD):\n",
    "            logger.error(\"IMAP email or app password not configured. Cannot fetch live emails.\")\n",
    "            print(\"Please ensure GMAIL_EMAIL and app_password are set in your .env file.\")\n",
    "            return\n",
    "        emails = fetch_imap_emails(GMAIL_IMAP_EMAIL, APP_PASSWORD, num_emails=5)\n",
    "        logger.debug(f\"Fetched {len(emails)} emails from IMAP.\")\n",
    "    elif data_source == 'j':\n",
    "        json_file = input(\"Enter path to JSON test data file (e.g., test_emails.json): \")\n",
    "        try:\n",
    "            with open(json_file, 'r') as f:\n",
    "                emails = json.load(f)\n",
    "            logger.debug(f\"Loaded {len(emails)} emails from {json_file}.\")\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"Error: JSON file not found at {json_file}\")\n",
    "            return\n",
    "        except json.JSONDecodeError:\n",
    "            logger.error(f\"Error: Could not decode JSON from {json_file}\")\n",
    "            return\n",
    "    else:\n",
    "        logger.warning(\"Invalid data source option. Exiting.\")\n",
    "        return\n",
    "\n",
    "    if not emails:\n",
    "        logger.info(\"No emails found to process.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nSelect an email to process:\")\n",
    "    for idx, email_item in enumerate(emails):\n",
    "        print(f\"{idx + 1}. Subject: {email_item.get('subject', 'No Subject')} | From: {email_item.get('sender', 'Unknown')}\")\n",
    "\n",
    "    try:\n",
    "        choice = int(input(\"Enter the number of the email you want to choose: \")) - 1\n",
    "        if choice < 0 or choice >= len(emails):\n",
    "            print(\"Invalid choice. Exiting.\")\n",
    "            return\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a number. Exiting.\")\n",
    "        return\n",
    "\n",
    "    selected_email = emails[choice]\n",
    "\n",
    "    state = EmailState(\n",
    "        emails=[selected_email],\n",
    "        current_email=selected_email,\n",
    "        history=[],\n",
    "        metadata={}\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Processing selected email ID: {selected_email.get('id', 'unknown')}\")\n",
    "    final_state = supervisor_langgraph(selected_email, state, your_name, recipient_name)\n",
    "\n",
    "    processed_email = final_state['current_email']\n",
    "\n",
    "    print(\"\\n--- Processing Complete ---\")\n",
    "    print(\"\\nGenerated Response:\\n\")\n",
    "    generated_response = processed_email.get(\"response\", \"No response generated.\")\n",
    "    print(generated_response)\n",
    "\n",
    "    if generated_response and \"No response gener\" not in generated_response:\n",
    "        print(\"\\n--- Action Options ---\")\n",
    "        # Use the SENDER_EMAIL and APP_PASSWORD from .env directly for sending/drafting\n",
    "        process_email_action(processed_email, your_name, SENDER_EMAIL, APP_PASSWORD)\n",
    "    else:\n",
    "        print(\"No valid response to send or draft.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "939da50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 20:20:14,266 - __main__ - INFO - Starting AI Email Agent.\n",
      "2025-07-24 20:20:42,153 - __main__ - INFO - Connecting to IMAP server: imap.gmail.com with username: ultopalto0@gmail.com\n",
      "2025-07-24 20:20:43,216 - __main__ - INFO - IMAP login successful.\n",
      "2025-07-24 20:20:43,792 - __main__ - INFO - Selected INBOX folder.\n",
      "2025-07-24 20:20:44,238 - __main__ - DEBUG - Found 3086 messages.\n",
      "2025-07-24 20:20:47,439 - __main__ - INFO - Successfully fetched 5 emails.\n",
      "2025-07-24 20:20:48,087 - __main__ - DEBUG - Fetched 5 emails from IMAP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select an email to process:\n",
      "1. Subject: Is 52,000 AED/month sufficient salary for a single man in Dubai? | From: Quora Digest <english-quora-digest@quora.com>\n",
      "2. Subject: Email Subject | From: ultopalto0@gmail.com\n",
      "3. Subject: Email Subject | From: ultopalto0@gmail.com\n",
      "4. Subject: No Subject | From: Unknown Sender\n",
      "5. Subject: Email Subject | From: ultopalto0@gmail.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 20:30:31,825 - __main__ - INFO - Processing selected email ID: 3083\n",
      "2025-07-24 20:30:31,828 - __main__ - INFO - Invoking LangGraph for email ID: 3083\n",
      "2025-07-24 20:30:31,847 - __main__ - INFO - Filtering node started for email ID: 3083\n",
      "2025-07-24 20:30:33,668 - __main__ - ERROR - Error classifying email 3083: Error code: 401 - {'error': {'message': 'No auth credentials found', 'code': 401}}\n",
      "2025-07-24 20:30:33,669 - __main__ - INFO - Email ID: 3083 classified as: needs_review\n",
      "2025-07-24 20:30:33,669 - __main__ - INFO - Email ID: 3083 not spam. Proceeding to summarization.\n",
      "2025-07-24 20:30:33,670 - __main__ - INFO - Summarization node started for email ID: 3083\n",
      "2025-07-24 20:30:34,112 - __main__ - ERROR - Error summarizing email 3083: Error code: 401 - {'error': {'message': 'No auth credentials found', 'code': 401}}\n",
      "2025-07-24 20:30:34,112 - __main__ - INFO - Email ID: 3083 summarized.\n",
      "2025-07-24 20:30:34,113 - __main__ - INFO - Response generation node started for email ID: 3083\n",
      "2025-07-24 20:30:34,521 - __main__ - ERROR - Error generating response for email 3083: Error code: 401 - {'error': {'message': 'No auth credentials found', 'code': 401}}\n",
      "2025-07-24 20:30:34,522 - __main__ - INFO - Email ID: 3083 flagged for human review by supervisor logic.\n",
      "2025-07-24 20:30:34,523 - __main__ - INFO - Email ID: 3083 flagged for human review.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Human Review Required ---\n",
      "Original Subject: Email Subject\n",
      "Original Sender: ultopalto0@gmail.com\n",
      "Summary: Could not generate summary.\n",
      "\n",
      "AI Generated Response:\n",
      "Subject: Re: Email Subject\n",
      "\n",
      "Hi rakesh,\n",
      "\n",
      "I apologize, but I was unable to generate a response at this time. Please review the original email.\n",
      "\n",
      "Best regards,\n",
      "ujjwal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 20:30:55,811 - __main__ - INFO - Human accepted the response as is.\n",
      "2025-07-24 20:30:55,812 - __main__ - INFO - Email ID: 3083 response processed.\n",
      "2025-07-24 20:30:55,812 - __main__ - INFO - LangGraph processing finished for email ID: 3083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Complete ---\n",
      "\n",
      "Generated Response:\n",
      "\n",
      "Subject: Re: Email Subject\n",
      "\n",
      "Hi rakesh,\n",
      "\n",
      "I apologize, but I was unable to generate a response at this time. Please review the original email.\n",
      "\n",
      "Best regards,\n",
      "ujjwal\n",
      "\n",
      "--- Action Options ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 20:31:12,195 - __main__ - INFO - Email sent from ultopalto0@gmail.com to ['ultopalto0@gmail.com'] with subject 'Re: Email Subject'.\n",
      "2025-07-24 20:31:12,195 - __main__ - INFO - Email sent successfully.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_email_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f7d247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d36864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3030d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa96f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95689b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Building-LLMs-for-Production",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
